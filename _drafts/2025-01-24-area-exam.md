---
layout: post
title: On finally doing my area exam
---

# How I did my area exam

## 0. Picking a topic area
I have "decided" to do my area exam many times before now. Area exams are easy to postpone, because as PhD students it's easy to feel like there's always something more urgent to be working on. Over the years I have repeatedly fallen in to the trap of thinking of myself as a code- and paper-writing machine (which means no papers === I'm a complete failure! This machine is broken! Now I need to write twice as fast to make up for my humiliating failure! Etc.).

But besides the institutional requirement to do it, the main thing giving me forward momentum while working on my exam this time is having a clear idea of what I want to discuss. The area exam talk is about 40 minutes, which is both intimidatingly longer than any talk I've ever given _and_ shorter than I expected. You're not going to be able to sum up, say, all of _neurosymbolic programming_ or _planning for physical HRI_ in 40 minutes, and trying to do so will both waste your time and probably aggravate your latent anxiety disorder.

My topic is _AI for the faciltation of task handover_, which is (1) honestly still too broad for a 40-minute talk, but I'll do my best, and (2) an interesting choice because AI is *not* currently used to facilitate task handover (at least, not by anyone but me). The goal of the area exam is to demonstrate your understanding of the state of the art in your chosen area. Because my area is an application domain rather than a technique, and a currently-unrealized application domain at that, my talk will aim to look at the state of the various component technologies that would be applied to this problem space. This (in theory) lets me look at huge areas like LLM summarization and pick out the current papers that are most relevant to my desired application, even if they haven't actually been used for that purpose yet.

## 1. Deciding to do the area exam
If you have completed step 0, this should really only be the logistics step. Talk to your advisor to finalize your topic and, with their help, figure out 2 other faculty members that care about that topic and ask them to be on your committee. (This request does not have to be a big to-do -- a fairly short email with a description of your topic and a brief explanation of why you think they would be good to have on your committee given their expertise in XYZ worked just fine for me).

Now all that's left is to schedule that thing. Schedule yourself 2 weeks where you can focus mostly or completely on the exam, then send out a when2meet or equivalent to your commitee for some 1-2 week period after that. Once you've confirmed everyone's availability, send out that calendar invite, let your labmates know, and book a conference room (at CU you can do this at [CU EMS](https://ems.colorado.edu/)). I'd recommend also scheduling a practice talk a few days beforehand and inviting labmates and/or friends.

## 2. Making your outline
It took a fair amount of discussion with my advisor to figure out how to even go about outlining my topic. I had already done a fair amount of reading on all the component areas I wanted to touch on, but didn't know exactly what papers I would be discussion or what structure I would use. After much consideration I decided on taxonomizing the component parts of the task handover problem this way:

A. **sensing and encoding** of task-relevant information
B. **model updates** i.e. selecting what information to convey at handover
C. **communication** of task information at handover

My advisor then recommended I pick 2 relevant papers for each of these problem spaces, so 6 papers total. This was no easy task: it's an imperfect taxonomy, for one, and trying to decide the best papers to talk about for each sub-area was still like trying to find two needles in a very large haystack, with many different types of hay, so you don't know if you should get needles from a representatively broad sample of the hay or just choose some needles from one section of hay so that your needles feel more unified but potentially also more redundant, and some of the hay is behind a paywall so you can't tell if there's a needle in there, and also it's winter in Colorado so it's pitch dark and 0 degrees at 4pm and you want to go home.

The paper shortlist I sent to my advisor looked like this:

> A. *sensing and encoding* of task-relevant information
> * Zhang et al. Hierarchical Cross-Modality Semantic Correlation Learning Model for Multimodal Summarization - a recent-ish (2022) and well-cited paper that had a lot of success on summarization metrics by using semantic correlation learning to combine image and textual data into a single representation and text output. This paper showcases one of many strategies that can be used to extract meaning from multimodal input, making AI better able to recover task relevant information from the world around it. (I think this is the weakest link relevance-wise, so I am kind of shopping for a replacement for it. But, I also felt like it might be strange not to include something about VLMs/LLMs given how significant the strides have been, and this paper in particular has both good results and an interesting approach that allows the system to leverage both input modalities synergistically)
> * Wakayama & Ahmed, Probabilistic Semantic Data Association for Collaborative Human-Robot Sensing. This is one of Nisar’s papers obviously, and demonstrates a method to integrate robot sensor data with human-provided semantic information, with the goal of addressing situations where human info is erroneous or ambiguous. This paper highlights how by cleverly applying priors over the world state to incoming sensor data and integrating that sensor data accordingly, human-AI collaboration can produce a more complete world/task model than either could produce alone, representing a major way AI can support the handover process in this first information-gathering stage.
>
> B. *model updates*: selecting what information to convey at handover
> * Tabrez, SPEAR (policy elicitation). SPEAR uses the goal of policy elicitation to determine how best to update the user’s reward function via Boolean algebra and an MIL to optimize for coverage and conciseness.
> * Chen et al, MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication. This paper seeks to answer how a robot can determine “what, when, and how” to inform the user about (I’m more interested in the what). I’m still wrapping my head around the details of their methods, but their system aims to choose what state information to communicate based on what would most affect the human’s decision-making. The robot samples possible future trajectories using its own self-model and a learned human model to determine this.
>
> C. *communication* of task information at handover
> Note: The papers here could just as easily fit into the other two categories and I’m pretty unsure about putting them here. My current reasoning for having them here is that, compared to the papers in section 2, both are less concerned with determining what model updates to apply and more concerned with how those updates can be delivered via natural language communication. I had originally thought about focusing more on multimodal summarization and/or autonomous vehicle control takeover work here, but the narrative felt more scattered (to me).
> * Hayes and Shah. Improving Robot Controller Transparency Through Autonomous Policy Explanation. This work presents a system for generating a language explanation (either as a general summary or in response to query) of a policy from the robot’s task model. (I also considered putting this in section 1, since it’s a method of encoding policy information into language).
> * Charkraborti et al., Plan Explanations as Model Reconciliation -- An Empirical Study. This paper characterizes the model reconciliation process really well and explores the various kinds of explanations that can convey a particular model difference (model patch explanations vs plan patch explanations vs. minimally complete explanations… etc.)

